getwd()
setwd("C:/Users/bharathkumar/Documents/R")

library('xlsx')
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales') # visualization
library('dplyr') # data manipulation
library('mice') # imputation
library('randomForest') # classification algorithm
library('methods')
library('glmnet')
library('pROC')
library('Matrix')
library('xgboost')
library('Ckmeans.1d.dp')
library('corrplot')
library('class')

cusData <- read.xlsx("mydata.xlsx", sheetName = 'Data')

str(cusData)
summary(cusData)

#Replacing MISSING values with NA
cusData[ cusData == "MISSING" ] <- NA
cusData[ cusData == "" ] <- NA
cusData$dummy_quote_value <- as.numeric(cusData$dummy_quote_value)
summary(cusData)
str(cusData)

#Mice package
md.pattern(cusData)

library(VIM)
aggr_plot <- aggr(cusData, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(cusData), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

# Show number of missing dummy quote values
sum(is.na(cusData$dummy_quote_value))

# Make variables factors into factors
factor_vars <- c('Customer_ID','result_rank','provider_Nm','product_name',
                 'Sale_made', 'Sale_source')

cusData[factor_vars] <- lapply(cusData[factor_vars], function(x) as.factor(x))

# Set a random seed
set.seed(129)

# Perform mice imputation
mice_mod <- mice(cusData, m=5, maxit= 5, method = 'pmm', seed='500')
                 
summary(mice_mod)

# Save the complete output 
mice_output <- complete(mice_mod)

# Plot dummy quote distributions
par(mfrow=c(1,2))
hist(cusData$dummy_quote_value, freq=F, main='dummy quote: Original Data', 
     col='darkgreen', ylim=c(0,0.0004))
hist(mice_output$dummy_quote_value, freq=F, main='dummy quote: MICE Output', 
     col='lightgreen', ylim=c(0,0.0004))

# Replace dummy quote variable from the mice model.
cusData$dummy_quote_value <- mice_output$dummy_quote_value

# Show new number of missing Age values
sum(is.na(cusData$dummy_quote_value))

## 75% of the sample size
smp_size <- floor(0.75 * nrow(cusData))

## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(cusData)), size = smp_size)

train <- cusData[train_ind, ]
test <- cusData[-train_ind, ]

# Set a random seed
set.seed(754)

# Build the model (note: not all possible variables are used)
rf_model <- randomForest(factor(Sale_made) ~ result_rank + provider_Nm + product_name + dummy_quote_value,data = train)

# Show model error
plot(rf_model, ylim=c(0,1))
legend('topright', colnames(rf_model$err.rate), col=1:3, fill=1:3)

print(rf_model)
# Importance of each predictor.
print(importance(rf_model,type = 2)) 

# Get importance
importance    <- importance(rf_model)
varImportance <- data.frame(Variables = row.names(importance), 
                            Importance = round(importance[ ,'MeanDecreaseGini'],2))

# Create a rank variable based on importance
rankImportance <- varImportance %>%
  mutate(Rank = paste0('#',dense_rank(desc(Importance))))

# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance), 
                           y = Importance, fill = Importance)) +
  geom_bar(stat='identity') + 
  geom_text(aes(x = Variables, y = 0.5, label = Rank),
            hjust=0, vjust=0.55, size = 4, colour = 'red') +
  labs(x = 'Variables') +
  coord_flip() + 
  theme_few()

# Predict using the test set
prediction <- predict(rf_model, test)

table(prediction,test$Sale_made)
